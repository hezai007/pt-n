[2022-09-01 19:10:14,753 INFO train.py line 119 29919] arch: pointtransformer_seg_repro
base_lr: 0.5
batch_size: 16
batch_size_test: 4
batch_size_val: 4
classes: 13
data_name: s3dis
data_root: dataset/s3dis/trainval_fullarea
dist_backend: nccl
dist_url: tcp://localhost:8888
distributed: False
drop_rate: 0.5
epochs: 100
eval_freq: 1
evaluate: True
fea_dim: 6
ignore_label: 255
loop: 30
manual_seed: 7777
model_path: None
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: False
names_path: data/s3dis/s3dis_names.txt
ngpus_per_node: 1
print_freq: 1
rank: 0
resume: None
save_folder: None
save_freq: 1
save_path: exp/s3dis/pointtransformer_repro
split: val
start_epoch: 0
step_epoch: 30
sync_bn: False
test_area: 5
test_gpu: [0]
test_list: dataset/s3dis/list/val5.txt
test_list_full: dataset/s3dis/list/val5_full.txt
test_workers: 4
train_gpu: [3]
use_xyz: True
voxel_max: 80000
voxel_size: 0.04
weight: None
weight_decay: 0.0001
workers: 16
world_size: 1
[2022-09-01 19:10:14,753 INFO train.py line 120 29919] => creating model ...
[2022-09-01 19:10:14,753 INFO train.py line 121 29919] Classes: 13
[2022-09-01 19:10:14,753 INFO train.py line 122 29919] PointTransformerSeg(
  (enc1): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=6, out_features=32, bias=False)
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc2): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=35, out_features=64, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc3): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=67, out_features=128, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc4): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=131, out_features=256, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc5): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=259, out_features=512, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec5): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec4): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec3): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec2): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec1): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=32, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=32, out_features=13, bias=True)
  )
)
/dev/shm/Area_1_WC_1
/dev/shm/Area_1_conferenceRoom_1
/dev/shm/Area_1_conferenceRoom_2
/dev/shm/Area_1_copyRoom_1
/dev/shm/Area_1_hallway_1
/dev/shm/Area_1_hallway_2
/dev/shm/Area_1_hallway_3
/dev/shm/Area_1_hallway_4
/dev/shm/Area_1_hallway_5
/dev/shm/Area_1_hallway_6
/dev/shm/Area_1_hallway_7
/dev/shm/Area_1_hallway_8
/dev/shm/Area_1_office_1
/dev/shm/Area_1_office_10
/dev/shm/Area_1_office_11
/dev/shm/Area_1_office_12
/dev/shm/Area_1_office_13
/dev/shm/Area_1_office_14
/dev/shm/Area_1_office_15
/dev/shm/Area_1_office_16
/dev/shm/Area_1_office_17
/dev/shm/Area_1_office_18
/dev/shm/Area_1_office_19
/dev/shm/Area_1_office_2
/dev/shm/Area_1_office_20
/dev/shm/Area_1_office_21
/dev/shm/Area_1_office_22
/dev/shm/Area_1_office_23
/dev/shm/Area_1_office_24
/dev/shm/Area_1_office_25
/dev/shm/Area_1_office_26
/dev/shm/Area_1_office_27
/dev/shm/Area_1_office_28
/dev/shm/Area_1_office_29
/dev/shm/Area_1_office_3
/dev/shm/Area_1_office_30
/dev/shm/Area_1_office_31
/dev/shm/Area_1_office_4
/dev/shm/Area_1_office_5
/dev/shm/Area_1_office_6
/dev/shm/Area_1_office_7
/dev/shm/Area_1_office_8
/dev/shm/Area_1_office_9
/dev/shm/Area_1_pantry_1
/dev/shm/Area_2_WC_1
/dev/shm/Area_2_WC_2
/dev/shm/Area_2_auditorium_1
/dev/shm/Area_2_auditorium_2
/dev/shm/Area_2_conferenceRoom_1
/dev/shm/Area_2_hallway_1
/dev/shm/Area_2_hallway_10
/dev/shm/Area_2_hallway_11
/dev/shm/Area_2_hallway_12
/dev/shm/Area_2_hallway_2
/dev/shm/Area_2_hallway_3
/dev/shm/Area_2_hallway_4
/dev/shm/Area_2_hallway_5
/dev/shm/Area_2_hallway_6
/dev/shm/Area_2_hallway_7
/dev/shm/Area_2_hallway_8
/dev/shm/Area_2_hallway_9
/dev/shm/Area_2_office_1
/dev/shm/Area_2_office_10
/dev/shm/Area_2_office_11
/dev/shm/Area_2_office_12
/dev/shm/Area_2_office_13
/dev/shm/Area_2_office_14
/dev/shm/Area_2_office_2
/dev/shm/Area_2_office_3
/dev/shm/Area_2_office_4
/dev/shm/Area_2_office_5
/dev/shm/Area_2_office_6
/dev/shm/Area_2_office_7
/dev/shm/Area_2_office_8
/dev/shm/Area_2_office_9
/dev/shm/Area_2_storage_1
/dev/shm/Area_2_storage_2
/dev/shm/Area_2_storage_3
/dev/shm/Area_2_storage_4
/dev/shm/Area_2_storage_5
/dev/shm/Area_2_storage_6
/dev/shm/Area_2_storage_7
/dev/shm/Area_2_storage_8
/dev/shm/Area_2_storage_9
/dev/shm/Area_3_WC_1
/dev/shm/Area_3_WC_2
/dev/shm/Area_3_conferenceRoom_1
/dev/shm/Area_3_hallway_1
/dev/shm/Area_3_hallway_2
/dev/shm/Area_3_hallway_3
/dev/shm/Area_3_hallway_4
/dev/shm/Area_3_hallway_5
/dev/shm/Area_3_hallway_6
/dev/shm/Area_3_lounge_1
/dev/shm/Area_3_lounge_2
/dev/shm/Area_3_office_1
/dev/shm/Area_3_office_10
/dev/shm/Area_3_office_2
/dev/shm/Area_3_office_3
/dev/shm/Area_3_office_4
/dev/shm/Area_3_office_5
/dev/shm/Area_3_office_6
/dev/shm/Area_3_office_7
/dev/shm/Area_3_office_8
/dev/shm/Area_3_office_9
/dev/shm/Area_3_storage_1
/dev/shm/Area_3_storage_2
/dev/shm/Area_4_WC_1
/dev/shm/Area_4_WC_2
/dev/shm/Area_4_WC_3
/dev/shm/Area_4_WC_4
/dev/shm/Area_4_conferenceRoom_1
/dev/shm/Area_4_conferenceRoom_2
/dev/shm/Area_4_conferenceRoom_3
/dev/shm/Area_4_hallway_1
/dev/shm/Area_4_hallway_10
/dev/shm/Area_4_hallway_11
/dev/shm/Area_4_hallway_12
/dev/shm/Area_4_hallway_13
/dev/shm/Area_4_hallway_14
/dev/shm/Area_4_hallway_2
/dev/shm/Area_4_hallway_3
/dev/shm/Area_4_hallway_4
/dev/shm/Area_4_hallway_5
/dev/shm/Area_4_hallway_6
/dev/shm/Area_4_hallway_7
/dev/shm/Area_4_hallway_8
/dev/shm/Area_4_hallway_9
/dev/shm/Area_4_lobby_1
/dev/shm/Area_4_lobby_2
/dev/shm/Area_4_office_1
/dev/shm/Area_4_office_10
/dev/shm/Area_4_office_11
/dev/shm/Area_4_office_12
/dev/shm/Area_4_office_13
/dev/shm/Area_4_office_14
/dev/shm/Area_4_office_15
/dev/shm/Area_4_office_16
/dev/shm/Area_4_office_17
/dev/shm/Area_4_office_18
/dev/shm/Area_4_office_19
/dev/shm/Area_4_office_2
/dev/shm/Area_4_office_20
/dev/shm/Area_4_office_21
/dev/shm/Area_4_office_22
/dev/shm/Area_4_office_3
/dev/shm/Area_4_office_4
/dev/shm/Area_4_office_5
/dev/shm/Area_4_office_6
/dev/shm/Area_4_office_7
/dev/shm/Area_4_office_8
/dev/shm/Area_4_office_9
/dev/shm/Area_4_storage_1
/dev/shm/Area_4_storage_2
/dev/shm/Area_4_storage_3
/dev/shm/Area_4_storage_4
/dev/shm/Area_6_conferenceRoom_1
/dev/shm/Area_6_copyRoom_1
/dev/shm/Area_6_hallway_1
/dev/shm/Area_6_hallway_2
/dev/shm/Area_6_hallway_3
/dev/shm/Area_6_hallway_4
/dev/shm/Area_6_hallway_5
/dev/shm/Area_6_hallway_6
/dev/shm/Area_6_lounge_1
/dev/shm/Area_6_office_1
/dev/shm/Area_6_office_10
/dev/shm/Area_6_office_11
/dev/shm/Area_6_office_12
/dev/shm/Area_6_office_13
/dev/shm/Area_6_office_14
/dev/shm/Area_6_office_15
/dev/shm/Area_6_office_16
/dev/shm/Area_6_office_17
/dev/shm/Area_6_office_18
/dev/shm/Area_6_office_19
/dev/shm/Area_6_office_2
/dev/shm/Area_6_office_20
/dev/shm/Area_6_office_21
/dev/shm/Area_6_office_22
/dev/shm/Area_6_office_23
/dev/shm/Area_6_office_24
/dev/shm/Area_6_office_25
/dev/shm/Area_6_office_26
/dev/shm/Area_6_office_27
/dev/shm/Area_6_office_28
/dev/shm/Area_6_office_29
/dev/shm/Area_6_office_3
/dev/shm/Area_6_office_30
/dev/shm/Area_6_office_31
/dev/shm/Area_6_office_32
/dev/shm/Area_6_office_33
/dev/shm/Area_6_office_34
/dev/shm/Area_6_office_35
/dev/shm/Area_6_office_36
/dev/shm/Area_6_office_37
/dev/shm/Area_6_office_4
/dev/shm/Area_6_office_5
/dev/shm/Area_6_office_6
/dev/shm/Area_6_office_7
/dev/shm/Area_6_office_8
/dev/shm/Area_6_office_9
/dev/shm/Area_6_openspace_1
/dev/shm/Area_6_pantry_1
Totally 204 samples in train set.
/dev/shm/Area_5_WC_1
/dev/shm/Area_5_WC_2
/dev/shm/Area_5_conferenceRoom_1
/dev/shm/Area_5_conferenceRoom_2
/dev/shm/Area_5_conferenceRoom_3
/dev/shm/Area_5_hallway_1
/dev/shm/Area_5_hallway_10
/dev/shm/Area_5_hallway_11
/dev/shm/Area_5_hallway_12
/dev/shm/Area_5_hallway_13
/dev/shm/Area_5_hallway_14
/dev/shm/Area_5_hallway_15
/dev/shm/Area_5_hallway_2
/dev/shm/Area_5_hallway_3
/dev/shm/Area_5_hallway_4
/dev/shm/Area_5_hallway_5
/dev/shm/Area_5_hallway_6
/dev/shm/Area_5_hallway_7
/dev/shm/Area_5_hallway_8
/dev/shm/Area_5_hallway_9
/dev/shm/Area_5_lobby_1
/dev/shm/Area_5_office_1
/dev/shm/Area_5_office_10
/dev/shm/Area_5_office_11
/dev/shm/Area_5_office_12
/dev/shm/Area_5_office_13
/dev/shm/Area_5_office_14
/dev/shm/Area_5_office_15
/dev/shm/Area_5_office_16
/dev/shm/Area_5_office_17
/dev/shm/Area_5_office_18
/dev/shm/Area_5_office_19
/dev/shm/Area_5_office_2
/dev/shm/Area_5_office_20
/dev/shm/Area_5_office_21
/dev/shm/Area_5_office_22
/dev/shm/Area_5_office_23
/dev/shm/Area_5_office_24
/dev/shm/Area_5_office_25
/dev/shm/Area_5_office_26
/dev/shm/Area_5_office_27
/dev/shm/Area_5_office_28
/dev/shm/Area_5_office_29
/dev/shm/Area_5_office_3
/dev/shm/Area_5_office_30
/dev/shm/Area_5_office_31
/dev/shm/Area_5_office_32
/dev/shm/Area_5_office_33
/dev/shm/Area_5_office_34
/dev/shm/Area_5_office_35
/dev/shm/Area_5_office_36
/dev/shm/Area_5_office_37
/dev/shm/Area_5_office_38
/dev/shm/Area_5_office_39
/dev/shm/Area_5_office_4
/dev/shm/Area_5_office_40
/dev/shm/Area_5_office_41
/dev/shm/Area_5_office_42
/dev/shm/Area_5_office_5
/dev/shm/Area_5_office_6
/dev/shm/Area_5_office_7
/dev/shm/Area_5_office_8
/dev/shm/Area_5_office_9
/dev/shm/Area_5_pantry_1
/dev/shm/Area_5_storage_1
/dev/shm/Area_5_storage_2
/dev/shm/Area_5_storage_3
/dev/shm/Area_5_storage_4
Totally 68 samples in val set.
/dev/shm/Area_1_WC_1
/dev/shm/Area_1_conferenceRoom_1
/dev/shm/Area_1_conferenceRoom_2
/dev/shm/Area_1_copyRoom_1
/dev/shm/Area_1_hallway_1
/dev/shm/Area_1_hallway_2
/dev/shm/Area_1_hallway_3
/dev/shm/Area_1_hallway_4
/dev/shm/Area_1_hallway_5
/dev/shm/Area_1_hallway_6
/dev/shm/Area_1_hallway_7
/dev/shm/Area_1_hallway_8
/dev/shm/Area_1_office_1
/dev/shm/Area_1_office_10
/dev/shm/Area_1_office_11
/dev/shm/Area_1_office_12
/dev/shm/Area_1_office_13
/dev/shm/Area_1_office_14
/dev/shm/Area_1_office_15
/dev/shm/Area_1_office_16
/dev/shm/Area_1_office_17
/dev/shm/Area_1_office_18
/dev/shm/Area_1_office_19
/dev/shm/Area_1_office_2
/dev/shm/Area_1_office_20
/dev/shm/Area_1_office_21
/dev/shm/Area_1_office_22
/dev/shm/Area_1_office_23
/dev/shm/Area_1_office_24
/dev/shm/Area_1_office_25
/dev/shm/Area_1_office_26
/dev/shm/Area_1_office_27
/dev/shm/Area_1_office_28
/dev/shm/Area_1_office_29
/dev/shm/Area_1_office_3
/dev/shm/Area_1_office_30
/dev/shm/Area_1_office_31
/dev/shm/Area_1_office_4
/dev/shm/Area_1_office_5
/dev/shm/Area_1_office_6
/dev/shm/Area_1_office_7
/dev/shm/Area_1_office_8[2022-09-01 19:10:20,438 INFO train.py line 171 29919] train_data samples: '6120'

/dev/shm/Area_1_office_9
/dev/shm/Area_1_pantry_1
/dev/shm/Area_2_WC_1
/dev/shm/Area_2_WC_2
/dev/shm/Area_2_auditorium_1
/dev/shm/Area_2_auditorium_2
/dev/shm/Area_2_conferenceRoom_1
/dev/shm/Area_2_hallway_1
/dev/shm/Area_2_hallway_10
/dev/shm/Area_2_hallway_11
/dev/shm/Area_2_hallway_12
/dev/shm/Area_2_hallway_2
/dev/shm/Area_2_hallway_3
/dev/shm/Area_2_hallway_4
/dev/shm/Area_2_hallway_5
/dev/shm/Area_2_hallway_6
/dev/shm/Area_2_hallway_7
/dev/shm/Area_2_hallway_8
/dev/shm/Area_2_hallway_9
/dev/shm/Area_2_office_1
/dev/shm/Area_2_office_10
/dev/shm/Area_2_office_11
/dev/shm/Area_2_office_12
/dev/shm/Area_2_office_13
/dev/shm/Area_2_office_14
/dev/shm/Area_2_office_2
/dev/shm/Area_2_office_3
/dev/shm/Area_2_office_4
/dev/shm/Area_2_office_5
/dev/shm/Area_2_office_6
/dev/shm/Area_2_office_7
/dev/shm/Area_2_office_8
/dev/shm/Area_2_office_9
/dev/shm/Area_2_storage_1
/dev/shm/Area_2_storage_2
/dev/shm/Area_2_storage_3
/dev/shm/Area_2_storage_4
/dev/shm/Area_2_storage_5
/dev/shm/Area_2_storage_6
/dev/shm/Area_2_storage_7
/dev/shm/Area_2_storage_8
/dev/shm/Area_2_storage_9
/dev/shm/Area_3_WC_1
/dev/shm/Area_3_WC_2
/dev/shm/Area_3_conferenceRoom_1
/dev/shm/Area_3_hallway_1
/dev/shm/Area_3_hallway_2
/dev/shm/Area_3_hallway_3
/dev/shm/Area_3_hallway_4
/dev/shm/Area_3_hallway_5
/dev/shm/Area_3_hallway_6
/dev/shm/Area_3_lounge_1
/dev/shm/Area_3_lounge_2
/dev/shm/Area_3_office_1
/dev/shm/Area_3_office_10
/dev/shm/Area_3_office_2
/dev/shm/Area_3_office_3
/dev/shm/Area_3_office_4
/dev/shm/Area_3_office_5
/dev/shm/Area_3_office_6
/dev/shm/Area_3_office_7
/dev/shm/Area_3_office_8
/dev/shm/Area_3_office_9
/dev/shm/Area_3_storage_1
/dev/shm/Area_3_storage_2
/dev/shm/Area_4_WC_1
/dev/shm/Area_4_WC_2
/dev/shm/Area_4_WC_3
/dev/shm/Area_4_WC_4
/dev/shm/Area_4_conferenceRoom_1
/dev/shm/Area_4_conferenceRoom_2
/dev/shm/Area_4_conferenceRoom_3
/dev/shm/Area_4_hallway_1
/dev/shm/Area_4_hallway_10
/dev/shm/Area_4_hallway_11
/dev/shm/Area_4_hallway_12
/dev/shm/Area_4_hallway_13
/dev/shm/Area_4_hallway_14
/dev/shm/Area_4_hallway_2
/dev/shm/Area_4_hallway_3
/dev/shm/Area_4_hallway_4
/dev/shm/Area_4_hallway_5
/dev/shm/Area_4_hallway_6
/dev/shm/Area_4_hallway_7
/dev/shm/Area_4_hallway_8
/dev/shm/Area_4_hallway_9
/dev/shm/Area_4_lobby_1
/dev/shm/Area_4_lobby_2
/dev/shm/Area_4_office_1
/dev/shm/Area_4_office_10
/dev/shm/Area_4_office_11
/dev/shm/Area_4_office_12
/dev/shm/Area_4_office_13
/dev/shm/Area_4_office_14
/dev/shm/Area_4_office_15
/dev/shm/Area_4_office_16
/dev/shm/Area_4_office_17
/dev/shm/Area_4_office_18
/dev/shm/Area_4_office_19
/dev/shm/Area_4_office_2
/dev/shm/Area_4_office_20
/dev/shm/Area_4_office_21
/dev/shm/Area_4_office_22
/dev/shm/Area_4_office_3
/dev/shm/Area_4_office_4
/dev/shm/Area_4_office_5
/dev/shm/Area_4_office_6
/dev/shm/Area_4_office_7
/dev/shm/Area_4_office_8
/dev/shm/Area_4_office_9
/dev/shm/Area_4_storage_1
/dev/shm/Area_4_storage_2
/dev/shm/Area_4_storage_3
/dev/shm/Area_4_storage_4
/dev/shm/Area_6_conferenceRoom_1
/dev/shm/Area_6_copyRoom_1
/dev/shm/Area_6_hallway_1
/dev/shm/Area_6_hallway_2
/dev/shm/Area_6_hallway_3
/dev/shm/Area_6_hallway_4
/dev/shm/Area_6_hallway_5
/dev/shm/Area_6_hallway_6
/dev/shm/Area_6_lounge_1
/dev/shm/Area_6_office_1
/dev/shm/Area_6_office_10
/dev/shm/Area_6_office_11
/dev/shm/Area_6_office_12
/dev/shm/Area_6_office_13
/dev/shm/Area_6_office_14
/dev/shm/Area_6_office_15
/dev/shm/Area_6_office_16
/dev/shm/Area_6_office_17
/dev/shm/Area_6_office_18
/dev/shm/Area_6_office_19
/dev/shm/Area_6_office_2
/dev/shm/Area_6_office_20
/dev/shm/Area_6_office_21
/dev/shm/Area_6_office_22
/dev/shm/Area_6_office_23
/dev/shm/Area_6_office_24
/dev/shm/Area_6_office_25
/dev/shm/Area_6_office_26
/dev/shm/Area_6_office_27
/dev/shm/Area_6_office_28
/dev/shm/Area_6_office_29
/dev/shm/Area_6_office_3
/dev/shm/Area_6_office_30
/dev/shm/Area_6_office_31
/dev/shm/Area_6_office_32
/dev/shm/Area_6_office_33
/dev/shm/Area_6_office_34
/dev/shm/Area_6_office_35
/dev/shm/Area_6_office_36
/dev/shm/Area_6_office_37
/dev/shm/Area_6_office_4
/dev/shm/Area_6_office_5
/dev/shm/Area_6_office_6
/dev/shm/Area_6_office_7
/dev/shm/Area_6_office_8
/dev/shm/Area_6_office_9
/dev/shm/Area_6_openspace_1
/dev/shm/Area_6_pantry_1
Totally 204 samples in train set.
***********************************************************
<util.s3dis.S3DIS object at 0x7f497b5ffc10>
/dev/shm/Area_5_WC_1
/dev/shm/Area_5_WC_2
/dev/shm/Area_5_conferenceRoom_1
/dev/shm/Area_5_conferenceRoom_2
/dev/shm/Area_5_conferenceRoom_3
/dev/shm/Area_5_hallway_1
/dev/shm/Area_5_hallway_10
/dev/shm/Area_5_hallway_11
/dev/shm/Area_5_hallway_12
/dev/shm/Area_5_hallway_13
/dev/shm/Area_5_hallway_14
/dev/shm/Area_5_hallway_15
/dev/shm/Area_5_hallway_2
/dev/shm/Area_5_hallway_3
/dev/shm/Area_5_hallway_4
/dev/shm/Area_5_hallway_5
/dev/shm/Area_5_hallway_6
/dev/shm/Area_5_hallway_7
/dev/shm/Area_5_hallway_8
/dev/shm/Area_5_hallway_9
/dev/shm/Area_5_lobby_1
/dev/shm/Area_5_office_1
/dev/shm/Area_5_office_10
/dev/shm/Area_5_office_11
/dev/shm/Area_5_office_12
/dev/shm/Area_5_office_13
/dev/shm/Area_5_office_14
/dev/shm/Area_5_office_15
/dev/shm/Area_5_office_16
/dev/shm/Area_5_office_17
/dev/shm/Area_5_office_18
/dev/shm/Area_5_office_19
/dev/shm/Area_5_office_2
/dev/shm/Area_5_office_20
/dev/shm/Area_5_office_21
/dev/shm/Area_5_office_22
/dev/shm/Area_5_office_23
/dev/shm/Area_5_office_24
/dev/shm/Area_5_office_25
/dev/shm/Area_5_office_26
/dev/shm/Area_5_office_27
/dev/shm/Area_5_office_28
/dev/shm/Area_5_office_29
/dev/shm/Area_5_office_3
/dev/shm/Area_5_office_30
/dev/shm/Area_5_office_31
/dev/shm/Area_5_office_32
/dev/shm/Area_5_office_33
/dev/shm/Area_5_office_34
/dev/shm/Area_5_office_35
/dev/shm/Area_5_office_36
/dev/shm/Area_5_office_37
/dev/shm/Area_5_office_38
/dev/shm/Area_5_office_39
/dev/shm/Area_5_office_4
/dev/shm/Area_5_office_40
/dev/shm/Area_5_office_41
/dev/shm/Area_5_office_42
/dev/shm/Area_5_office_5
/dev/shm/Area_5_office_6
/dev/shm/Area_5_office_7
/dev/shm/Area_5_office_8
/dev/shm/Area_5_office_9
/dev/shm/Area_5_pantry_1
/dev/shm/Area_5_storage_1
/dev/shm/Area_5_storage_2
/dev/shm/Area_5_storage_3
/dev/shm/Area_5_storage_4
Totally 68 samples in val set.
