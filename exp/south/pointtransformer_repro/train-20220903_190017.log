[2022-09-03 19:00:18,455 INFO train_south.py line 122 13406] arch: pointtransformer_seg_repro
base_lr: 0.5
batch_size: 4
batch_size_test: 4
batch_size_val: 4
classes: 3
data_name: south
data_root: dataset/south/trainval_fullarea
dist_backend: nccl
dist_url: tcp://localhost:8888
distributed: False
drop_rate: 0.5
epochs: 150
eval_freq: 1
evaluate: True
fea_dim: 6
ignore_label: 255
loop: 30
manual_seed: 7777
model_path: None
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: False
names_path: data/south/south_names.txt
ngpus_per_node: 1
print_freq: 1
rank: 0
resume: None
save_folder: None
save_freq: 1
save_path: exp/south/pointtransformer_repro
split: val
start_epoch: 0
step_epoch: 30
sync_bn: False
test_area: 5
test_gpu: [4]
test_list: dataset/south/list/val.txt
test_list_full: dataset/south/list/val_full.txt
test_workers: 4
train_gpu: [4]
use_xyz: True
voxel_max: 80000
voxel_size: 0.04
weight: None
weight_decay: 0.0001
workers: 1
world_size: 1
[2022-09-03 19:00:18,455 INFO train_south.py line 123 13406] => creating model ...
[2022-09-03 19:00:18,455 INFO train_south.py line 124 13406] Classes: 3
[2022-09-03 19:00:18,455 INFO train_south.py line 125 13406] PointTransformerSeg(
  (enc1): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=6, out_features=32, bias=False)
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc2): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=35, out_features=64, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc3): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=67, out_features=128, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc4): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=131, out_features=256, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc5): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=259, out_features=512, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec5): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec4): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec3): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec2): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec1): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=32, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=32, out_features=3, bias=True)
  )
)
[2022-09-03 19:00:22,165 INFO train_south.py line 171 13406] train_data samples: '210'
Totally 7 samples in train set.
Totally 2 samples in val set.
Totally 7 samples in train set.
Totally 2 samples in val set.
/home/wanghe/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
[2022-09-03 19:00:30,939 INFO train_south.py line 279 13406] Epoch: [1/150][1/52] Data 6.192 (6.192) Batch 8.769 (8.769) Remain 18:59:52 Loss 1.1198 Accuracy 0.3336.
[2022-09-03 19:00:33,442 INFO train_south.py line 279 13406] Epoch: [1/150][2/52] Data 0.942 (3.567) Batch 2.504 (5.637) Remain 12:12:35 Loss 1.1107 Accuracy 0.3325.
[2022-09-03 19:00:35,361 INFO train_south.py line 279 13406] Epoch: [1/150][3/52] Data 0.362 (2.499) Batch 1.919 (4.398) Remain 09:31:27 Loss 1.1087 Accuracy 0.3348.
[2022-09-03 19:00:38,922 INFO train_south.py line 279 13406] Epoch: [1/150][4/52] Data 1.988 (2.371) Batch 3.561 (4.188) Remain 09:04:12 Loss 1.1065 Accuracy 0.3330.
[2022-09-03 19:00:43,273 INFO train_south.py line 279 13406] Epoch: [1/150][5/52] Data 2.785 (2.454) Batch 4.351 (4.221) Remain 09:08:21 Loss 1.1032 Accuracy 0.3338.
[2022-09-03 19:00:47,392 INFO train_south.py line 279 13406] Epoch: [1/150][6/52] Data 2.541 (2.468) Batch 4.119 (4.204) Remain 09:06:05 Loss 1.1051 Accuracy 0.3330.
[2022-09-03 19:00:49,420 INFO train_south.py line 279 13406] Epoch: [1/150][7/52] Data 0.479 (2.184) Batch 2.028 (3.893) Remain 08:25:38 Loss 1.1023 Accuracy 0.3340.
[2022-09-03 19:00:51,431 INFO train_south.py line 279 13406] Epoch: [1/150][8/52] Data 0.454 (1.968) Batch 2.011 (3.658) Remain 07:55:01 Loss 1.1010 Accuracy 0.3321.
[2022-09-03 19:00:54,278 INFO train_south.py line 279 13406] Epoch: [1/150][9/52] Data 1.292 (1.893) Batch 2.847 (3.568) Remain 07:43:15 Loss 1.1027 Accuracy 0.3329.
[2022-09-03 19:01:00,493 INFO train_south.py line 279 13406] Epoch: [1/150][10/52] Data 4.650 (2.168) Batch 6.216 (3.832) Remain 08:17:34 Loss 1.1006 Accuracy 0.3327.
[2022-09-03 19:01:03,947 INFO train_south.py line 279 13406] Epoch: [1/150][11/52] Data 1.906 (2.145) Batch 3.454 (3.798) Remain 08:13:03 Loss 1.1003 Accuracy 0.3333.
[2022-09-03 19:01:06,260 INFO train_south.py line 279 13406] Epoch: [1/150][12/52] Data 0.764 (2.029) Batch 2.312 (3.674) Remain 07:56:54 Loss 1.1012 Accuracy 0.3339.
[2022-09-03 19:01:08,495 INFO train_south.py line 279 13406] Epoch: [1/150][13/52] Data 0.675 (1.925) Batch 2.236 (3.564) Remain 07:42:29 Loss 1.0997 Accuracy 0.3356.
[2022-09-03 19:01:10,090 INFO train_south.py line 279 13406] Epoch: [1/150][14/52] Data 0.042 (1.791) Batch 1.594 (3.423) Remain 07:24:10 Loss 1.1000 Accuracy 0.3348.
[2022-09-03 19:01:15,954 INFO train_south.py line 279 13406] Epoch: [1/150][15/52] Data 4.303 (1.958) Batch 5.864 (3.586) Remain 07:45:14 Loss 1.1008 Accuracy 0.3324.
[2022-09-03 19:01:17,944 INFO train_south.py line 279 13406] Epoch: [1/150][16/52] Data 0.444 (1.864) Batch 1.990 (3.486) Remain 07:32:14 Loss 1.0994 Accuracy 0.3344.
[2022-09-03 19:01:21,721 INFO train_south.py line 279 13406] Epoch: [1/150][17/52] Data 2.213 (1.884) Batch 3.777 (3.503) Remain 07:34:24 Loss 1.0997 Accuracy 0.3319.
[2022-09-03 19:01:25,373 INFO train_south.py line 279 13406] Epoch: [1/150][18/52] Data 2.086 (1.895) Batch 3.653 (3.511) Remain 07:35:25 Loss 1.1000 Accuracy 0.3338.
[2022-09-03 19:01:31,561 INFO train_south.py line 279 13406] Epoch: [1/150][19/52] Data 4.627 (2.039) Batch 6.187 (3.652) Remain 07:53:37 Loss 1.0993 Accuracy 0.3331.
[2022-09-03 19:01:33,944 INFO train_south.py line 279 13406] Epoch: [1/150][20/52] Data 0.833 (1.979) Batch 2.383 (3.589) Remain 07:45:20 Loss 1.0994 Accuracy 0.3338.
[2022-09-03 19:01:36,251 INFO train_south.py line 279 13406] Epoch: [1/150][21/52] Data 0.755 (1.920) Batch 2.308 (3.528) Remain 07:37:22 Loss 1.0996 Accuracy 0.3337.
[2022-09-03 19:01:39,117 INFO train_south.py line 279 13406] Epoch: [1/150][22/52] Data 1.307 (1.893) Batch 2.865 (3.498) Remain 07:33:24 Loss 1.0990 Accuracy 0.3341.
[2022-09-03 19:01:41,201 INFO train_south.py line 279 13406] Epoch: [1/150][23/52] Data 0.527 (1.833) Batch 2.084 (3.436) Remain 07:25:23 Loss 1.0992 Accuracy 0.3333.
[2022-09-03 19:01:43,478 INFO train_south.py line 279 13406] Epoch: [1/150][24/52] Data 0.725 (1.787) Batch 2.277 (3.388) Remain 07:19:04 Loss 1.0995 Accuracy 0.3312.
[2022-09-03 19:01:45,960 INFO train_south.py line 279 13406] Epoch: [1/150][25/52] Data 0.930 (1.753) Batch 2.482 (3.352) Remain 07:14:19 Loss 1.0990 Accuracy 0.3325.
[2022-09-03 19:01:48,289 INFO train_south.py line 279 13406] Epoch: [1/150][26/52] Data 0.778 (1.715) Batch 2.329 (3.312) Remain 07:09:10 Loss 1.0991 Accuracy 0.3334.
[2022-09-03 19:01:50,234 INFO train_south.py line 279 13406] Epoch: [1/150][27/52] Data 0.390 (1.666) Batch 1.944 (3.262) Remain 07:02:32 Loss 1.0994 Accuracy 0.3335.
[2022-09-03 19:01:55,304 INFO train_south.py line 279 13406] Epoch: [1/150][28/52] Data 3.502 (1.732) Batch 5.070 (3.326) Remain 07:10:51 Loss 1.0989 Accuracy 0.3327.
[2022-09-03 19:01:57,284 INFO train_south.py line 279 13406] Epoch: [1/150][29/52] Data 0.420 (1.687) Batch 1.980 (3.280) Remain 07:04:47 Loss 1.0990 Accuracy 0.3329.
[2022-09-03 19:02:16,545 INFO train_south.py line 279 13406] Epoch: [1/150][30/52] Data 17.650 (2.219) Batch 19.261 (3.813) Remain 08:13:43 Loss 1.0991 Accuracy 0.3330.
[2022-09-03 19:02:24,345 INFO train_south.py line 279 13406] Epoch: [1/150][31/52] Data 6.219 (2.348) Batch 7.800 (3.941) Remain 08:30:18 Loss 1.0989 Accuracy 0.3331.
[2022-09-03 19:02:27,935 INFO train_south.py line 279 13406] Epoch: [1/150][32/52] Data 2.018 (2.337) Batch 3.591 (3.930) Remain 08:28:49 Loss 1.0989 Accuracy 0.3343.
[2022-09-03 19:02:36,601 INFO train_south.py line 279 13406] Epoch: [1/150][33/52] Data 7.115 (2.482) Batch 8.665 (4.074) Remain 08:47:20 Loss 1.0990 Accuracy 0.3337.
[2022-09-03 19:02:38,507 INFO train_south.py line 279 13406] Epoch: [1/150][34/52] Data 0.352 (2.420) Batch 1.906 (4.010) Remain 08:39:01 Loss 1.0988 Accuracy 0.3342.
[2022-09-03 19:02:42,286 INFO train_south.py line 279 13406] Epoch: [1/150][35/52] Data 2.189 (2.413) Batch 3.779 (4.003) Remain 08:38:05 Loss 1.0988 Accuracy 0.3328.
[2022-09-03 19:02:48,344 INFO train_south.py line 279 13406] Epoch: [1/150][36/52] Data 4.500 (2.471) Batch 6.058 (4.060) Remain 08:45:25 Loss 1.0990 Accuracy 0.3340.
[2022-09-03 19:02:50,755 INFO train_south.py line 279 13406] Epoch: [1/150][37/52] Data 0.855 (2.427) Batch 2.411 (4.016) Remain 08:39:34 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 19:02:52,902 INFO train_south.py line 279 13406] Epoch: [1/150][38/52] Data 0.598 (2.379) Batch 2.147 (3.967) Remain 08:33:09 Loss 1.0988 Accuracy 0.3339.
[2022-09-03 19:02:54,973 INFO train_south.py line 279 13406] Epoch: [1/150][39/52] Data 0.519 (2.331) Batch 2.071 (3.918) Remain 08:26:48 Loss 1.0988 Accuracy 0.3326.
[2022-09-03 19:02:57,085 INFO train_south.py line 279 13406] Epoch: [1/150][40/52] Data 0.541 (2.287) Batch 2.112 (3.873) Remain 08:20:53 Loss 1.0987 Accuracy 0.3334.
[2022-09-03 19:03:01,758 INFO train_south.py line 279 13406] Epoch: [1/150][41/52] Data 3.106 (2.307) Batch 4.673 (3.892) Remain 08:23:21 Loss 1.0988 Accuracy 0.3330.
[2022-09-03 19:03:03,558 INFO train_south.py line 279 13406] Epoch: [1/150][42/52] Data 0.240 (2.257) Batch 1.800 (3.843) Remain 08:16:50 Loss 1.0988 Accuracy 0.3336.
[2022-09-03 19:03:05,412 INFO train_south.py line 279 13406] Epoch: [1/150][43/52] Data 0.301 (2.212) Batch 1.855 (3.796) Remain 08:10:48 Loss 1.0987 Accuracy 0.3337.
[2022-09-03 19:03:07,210 INFO train_south.py line 279 13406] Epoch: [1/150][44/52] Data 0.245 (2.167) Batch 1.798 (3.751) Remain 08:04:52 Loss 1.0988 Accuracy 0.3329.
[2022-09-03 19:03:09,582 INFO train_south.py line 279 13406] Epoch: [1/150][45/52] Data 0.815 (2.137) Batch 2.372 (3.720) Remain 08:00:50 Loss 1.0987 Accuracy 0.3341.
[2022-09-03 19:03:11,364 INFO train_south.py line 279 13406] Epoch: [1/150][46/52] Data 0.225 (2.096) Batch 1.782 (3.678) Remain 07:55:20 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 19:03:16,437 INFO train_south.py line 279 13406] Epoch: [1/150][47/52] Data 3.501 (2.126) Batch 5.072 (3.708) Remain 07:59:06 Loss 1.0987 Accuracy 0.3325.
[2022-09-03 19:03:18,316 INFO train_south.py line 279 13406] Epoch: [1/150][48/52] Data 0.325 (2.088) Batch 1.879 (3.670) Remain 07:54:07 Loss 1.0987 Accuracy 0.3337.
[2022-09-03 19:03:20,280 INFO train_south.py line 279 13406] Epoch: [1/150][49/52] Data 0.407 (2.054) Batch 1.964 (3.635) Remain 07:49:34 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 19:03:22,108 INFO train_south.py line 279 13406] Epoch: [1/150][50/52] Data 0.273 (2.018) Batch 1.828 (3.599) Remain 07:44:50 Loss 1.0987 Accuracy 0.3346.
[2022-09-03 19:03:24,258 INFO train_south.py line 279 13406] Epoch: [1/150][51/52] Data 0.593 (1.990) Batch 2.150 (3.570) Remain 07:41:06 Loss 1.0987 Accuracy 0.3348.
[2022-09-03 19:03:26,109 INFO train_south.py line 279 13406] Epoch: [1/150][52/52] Data 0.298 (1.958) Batch 1.852 (3.537) Remain 07:36:47 Loss 1.0987 Accuracy 0.3337.
[2022-09-03 19:03:26,225 INFO train_south.py line 301 13406] Train result at epoch [1/150]: mIoU/mAcc/allAcc 0.1974/0.3334/0.3334.
[2022-09-03 19:03:26,228 INFO train_south.py line 307 13406] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 19:04:08,438 INFO train_south.py line 346 13406] Test: [1/1] Data 2.740 (2.740) Batch 42.204 (42.204) Loss 1.0987 (1.0987) Accuracy 0.3331.
[2022-09-03 19:04:08,570 INFO train_south.py line 363 13406] Val result: mIoU/mAcc/allAcc 0.1901/0.3331/0.3331.
[2022-09-03 19:04:08,571 INFO train_south.py line 365 13406] Class_0 Result: iou/accuracy 0.2041/0.3457.
[2022-09-03 19:04:08,571 INFO train_south.py line 365 13406] Class_1 Result: iou/accuracy 0.2512/0.5038.
[2022-09-03 19:04:08,571 INFO train_south.py line 365 13406] Class_2 Result: iou/accuracy 0.1151/0.1498.
[2022-09-03 19:04:08,571 INFO train_south.py line 366 13406] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2022-09-03 19:04:08,572 INFO train_south.py line 217 13406] Saving checkpoint to: exp/south/pointtransformer_repro/model/model_last.pth
[2022-09-03 19:04:08,885 INFO train_south.py line 221 13406] Best validation mIoU updated to: 0.1901
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 19:04:17,712 INFO train_south.py line 279 13406] Epoch: [2/150][1/52] Data 7.153 (7.153) Batch 8.717 (8.717) Remain 18:45:27 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 19:04:20,503 INFO train_south.py line 279 13406] Epoch: [2/150][2/52] Data 1.236 (4.195) Batch 2.791 (5.754) Remain 12:22:47 Loss 1.0987 Accuracy 0.3335.
[2022-09-03 19:04:22,422 INFO train_south.py line 279 13406] Epoch: [2/150][3/52] Data 0.368 (2.919) Batch 1.920 (4.476) Remain 09:37:44 Loss 1.0987 Accuracy 0.3330.
[2022-09-03 19:04:24,275 INFO train_south.py line 279 13406] Epoch: [2/150][4/52] Data 0.301 (2.264) Batch 1.852 (3.820) Remain 08:13:00 Loss 1.0987 Accuracy 0.3324.
[2022-09-03 19:04:27,752 INFO train_south.py line 279 13406] Epoch: [2/150][5/52] Data 1.907 (2.193) Batch 3.478 (3.751) Remain 08:04:07 Loss 1.0987 Accuracy 0.3339.
[2022-09-03 19:04:31,189 INFO train_south.py line 279 13406] Epoch: [2/150][6/52] Data 1.877 (2.140) Batch 3.436 (3.699) Remain 07:57:16 Loss 1.0987 Accuracy 0.3322.
