[2022-09-03 18:49:29,108 INFO train_south.py line 122 39176] arch: pointtransformer_seg_repro
base_lr: 0.5
batch_size: 4
batch_size_test: 4
batch_size_val: 4
classes: 3
data_name: south
data_root: dataset/south/trainval_fullarea
dist_backend: nccl
dist_url: tcp://localhost:8888
distributed: False
drop_rate: 0.5
epochs: 150
eval_freq: 1
evaluate: True
fea_dim: 6
ignore_label: 255
loop: 30
manual_seed: 7777
model_path: None
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: False
names_path: data/south/south_names.txt
ngpus_per_node: 1
print_freq: 1
rank: 0
resume: None
save_folder: None
save_freq: 1
save_path: exp/south/pointtransformer_repro
split: val
start_epoch: 0
step_epoch: 30
sync_bn: False
test_area: 5
test_gpu: [4]
test_list: dataset/south/list/val.txt
test_list_full: dataset/south/list/val_full.txt
test_workers: 4
train_gpu: [4]
use_xyz: True
voxel_max: 80000
voxel_size: 0.04
weight: None
weight_decay: 0.0001
workers: 16
world_size: 1
[2022-09-03 18:49:29,108 INFO train_south.py line 123 39176] => creating model ...
[2022-09-03 18:49:29,108 INFO train_south.py line 124 39176] Classes: 3
[2022-09-03 18:49:29,109 INFO train_south.py line 125 39176] PointTransformerSeg(
  (enc1): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=6, out_features=32, bias=False)
      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc2): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=35, out_features=64, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc3): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=67, out_features=128, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc4): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=131, out_features=256, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (enc5): Sequential(
    (0): TransitionDown(
      (linear): Linear(in_features=259, out_features=512, bias=False)
      (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec5): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=512, out_features=512, bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=512, out_features=512, bias=True)
        (linear_k): Linear(in_features=512, out_features=512, bias=True)
        (linear_v): Linear(in_features=512, out_features=512, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=512, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=512, out_features=64, bias=True)
          (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=64, out_features=64, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=512, out_features=512, bias=False)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec4): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=256, out_features=256, bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=256, out_features=256, bias=True)
        (linear_k): Linear(in_features=256, out_features=256, bias=True)
        (linear_v): Linear(in_features=256, out_features=256, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=256, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
          (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=32, out_features=32, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=256, out_features=256, bias=False)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec3): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=128, out_features=128, bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=128, out_features=128, bias=True)
        (linear_k): Linear(in_features=128, out_features=128, bias=True)
        (linear_v): Linear(in_features=128, out_features=128, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=128, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=16, bias=True)
          (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=16, out_features=16, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=128, out_features=128, bias=False)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec2): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=64, out_features=64, bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=64, out_features=64, bias=True)
        (linear_k): Linear(in_features=64, out_features=64, bias=True)
        (linear_v): Linear(in_features=64, out_features=64, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=64, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=64, out_features=8, bias=True)
          (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=8, out_features=8, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=64, out_features=64, bias=False)
      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (dec1): Sequential(
    (0): TransitionUp(
      (linear1): Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (linear2): Sequential(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (1): PointTransformerBlock(
      (linear1): Linear(in_features=32, out_features=32, bias=False)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (transformer2): PointTransformerLayer(
        (linear_q): Linear(in_features=32, out_features=32, bias=True)
        (linear_k): Linear(in_features=32, out_features=32, bias=True)
        (linear_v): Linear(in_features=32, out_features=32, bias=True)
        (linear_p): Sequential(
          (0): Linear(in_features=3, out_features=3, bias=True)
          (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=32, bias=True)
        )
        (linear_w): Sequential(
          (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=4, bias=True)
          (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=4, out_features=4, bias=True)
        )
        (softmax): Softmax(dim=1)
      )
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear3): Linear(in_features=32, out_features=32, bias=False)
      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=32, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=32, out_features=3, bias=True)
  )
)
[2022-09-03 18:49:32,621 INFO train_south.py line 171 39176] train_data samples: '210'
Totally 7 samples in train set.
Totally 2 samples in val set.
Totally 7 samples in train set.
Totally 2 samples in val set.
/home/wanghe/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
[2022-09-03 18:50:38,809 INFO train_south.py line 279 39176] Epoch: [1/150][1/52] Data 63.495 (63.495) Batch 66.184 (66.184) Remain 143:22:52 Loss 1.1198 Accuracy 0.3336.
[2022-09-03 18:50:58,475 INFO train_south.py line 279 39176] Epoch: [1/150][2/52] Data 18.053 (40.774) Batch 19.666 (42.925) Remain 92:58:49 Loss 1.1116 Accuracy 0.3331.
[2022-09-03 18:51:00,027 INFO train_south.py line 279 39176] Epoch: [1/150][3/52] Data 0.002 (27.183) Batch 1.552 (29.134) Remain 63:05:57 Loss 1.1085 Accuracy 0.3342.
[2022-09-03 18:51:12,850 INFO train_south.py line 279 39176] Epoch: [1/150][4/52] Data 11.228 (23.194) Batch 12.824 (25.056) Remain 54:15:39 Loss 1.1056 Accuracy 0.3324.
[2022-09-03 18:51:14,398 INFO train_south.py line 279 39176] Epoch: [1/150][5/52] Data 0.001 (18.556) Batch 1.548 (20.355) Remain 44:04:24 Loss 1.1035 Accuracy 0.3322.
[2022-09-03 18:51:15,963 INFO train_south.py line 279 39176] Epoch: [1/150][6/52] Data 0.002 (15.463) Batch 1.564 (17.223) Remain 37:17:15 Loss 1.1052 Accuracy 0.3330.
[2022-09-03 18:51:17,608 INFO train_south.py line 279 39176] Epoch: [1/150][7/52] Data 0.002 (13.255) Batch 1.646 (14.998) Remain 32:27:56 Loss 1.1017 Accuracy 0.3346.
[2022-09-03 18:51:19,169 INFO train_south.py line 279 39176] Epoch: [1/150][8/52] Data 0.003 (11.598) Batch 1.560 (13.318) Remain 28:49:33 Loss 1.1012 Accuracy 0.3332.
[2022-09-03 18:51:20,732 INFO train_south.py line 279 39176] Epoch: [1/150][9/52] Data 0.003 (10.310) Batch 1.563 (12.012) Remain 25:59:44 Loss 1.1017 Accuracy 0.3351.
[2022-09-03 18:51:22,292 INFO train_south.py line 279 39176] Epoch: [1/150][10/52] Data 0.001 (9.279) Batch 1.560 (10.967) Remain 23:43:50 Loss 1.1003 Accuracy 0.3325.
[2022-09-03 18:51:23,843 INFO train_south.py line 279 39176] Epoch: [1/150][11/52] Data 0.001 (8.435) Batch 1.552 (10.111) Remain 21:52:32 Loss 1.0998 Accuracy 0.3342.
[2022-09-03 18:51:25,415 INFO train_south.py line 279 39176] Epoch: [1/150][12/52] Data 0.001 (7.733) Batch 1.572 (9.399) Remain 20:20:00 Loss 1.1007 Accuracy 0.3330.
[2022-09-03 18:51:27,000 INFO train_south.py line 279 39176] Epoch: [1/150][13/52] Data 0.004 (7.138) Batch 1.585 (8.798) Remain 19:01:50 Loss 1.1000 Accuracy 0.3335.
[2022-09-03 18:51:28,568 INFO train_south.py line 279 39176] Epoch: [1/150][14/52] Data 0.003 (6.628) Batch 1.568 (8.282) Remain 17:54:41 Loss 1.0997 Accuracy 0.3341.
[2022-09-03 18:51:30,175 INFO train_south.py line 279 39176] Epoch: [1/150][15/52] Data 0.001 (6.187) Batch 1.606 (7.837) Remain 16:56:48 Loss 1.1001 Accuracy 0.3340.
[2022-09-03 18:51:31,752 INFO train_south.py line 279 39176] Epoch: [1/150][16/52] Data 0.004 (5.800) Batch 1.578 (7.445) Remain 16:05:55 Loss 1.0995 Accuracy 0.3329.
[2022-09-03 18:51:33,321 INFO train_south.py line 279 39176] Epoch: [1/150][17/52] Data 0.001 (5.459) Batch 1.568 (7.100) Remain 15:20:57 Loss 1.0993 Accuracy 0.3339.
[2022-09-03 18:51:34,894 INFO train_south.py line 279 39176] Epoch: [1/150][18/52] Data 0.002 (5.156) Batch 1.574 (6.793) Remain 14:41:01 Loss 1.0998 Accuracy 0.3338.
[2022-09-03 18:51:36,678 INFO train_south.py line 279 39176] Epoch: [1/150][19/52] Data 0.001 (4.885) Batch 1.784 (6.529) Remain 14:06:43 Loss 1.0993 Accuracy 0.3338.
[2022-09-03 18:51:53,180 INFO train_south.py line 279 39176] Epoch: [1/150][20/52] Data 14.923 (5.387) Batch 16.501 (7.028) Remain 15:11:15 Loss 1.0993 Accuracy 0.3330.
[2022-09-03 18:51:54,728 INFO train_south.py line 279 39176] Epoch: [1/150][21/52] Data 0.001 (5.130) Batch 1.549 (6.767) Remain 14:37:19 Loss 1.0995 Accuracy 0.3342.
[2022-09-03 18:51:56,363 INFO train_south.py line 279 39176] Epoch: [1/150][22/52] Data 0.002 (4.897) Batch 1.634 (6.534) Remain 14:06:57 Loss 1.0993 Accuracy 0.3322.
[2022-09-03 18:51:57,921 INFO train_south.py line 279 39176] Epoch: [1/150][23/52] Data 0.001 (4.684) Batch 1.558 (6.317) Remain 13:38:49 Loss 1.0992 Accuracy 0.3331.
[2022-09-03 18:51:59,481 INFO train_south.py line 279 39176] Epoch: [1/150][24/52] Data 0.001 (4.489) Batch 1.560 (6.119) Remain 13:13:01 Loss 1.0994 Accuracy 0.3327.
[2022-09-03 18:52:01,040 INFO train_south.py line 279 39176] Epoch: [1/150][25/52] Data 0.002 (4.310) Batch 1.560 (5.937) Remain 12:49:17 Loss 1.0990 Accuracy 0.3339.
[2022-09-03 18:52:02,593 INFO train_south.py line 279 39176] Epoch: [1/150][26/52] Data 0.001 (4.144) Batch 1.553 (5.768) Remain 12:27:20 Loss 1.0991 Accuracy 0.3315.
[2022-09-03 18:52:04,150 INFO train_south.py line 279 39176] Epoch: [1/150][27/52] Data 0.002 (3.990) Batch 1.557 (5.612) Remain 12:07:02 Loss 1.0991 Accuracy 0.3350.
[2022-09-03 18:52:05,713 INFO train_south.py line 279 39176] Epoch: [1/150][28/52] Data 0.001 (3.848) Batch 1.563 (5.467) Remain 11:48:12 Loss 1.0989 Accuracy 0.3337.
[2022-09-03 18:52:07,272 INFO train_south.py line 279 39176] Epoch: [1/150][29/52] Data 0.002 (3.715) Batch 1.559 (5.333) Remain 11:30:40 Loss 1.0988 Accuracy 0.3334.
[2022-09-03 18:52:08,826 INFO train_south.py line 279 39176] Epoch: [1/150][30/52] Data 0.001 (3.592) Batch 1.554 (5.207) Remain 11:14:16 Loss 1.0991 Accuracy 0.3323.
[2022-09-03 18:52:10,429 INFO train_south.py line 279 39176] Epoch: [1/150][31/52] Data 0.001 (3.476) Batch 1.603 (5.090) Remain 10:59:07 Loss 1.0989 Accuracy 0.3339.
[2022-09-03 18:52:12,013 INFO train_south.py line 279 39176] Epoch: [1/150][32/52] Data 0.001 (3.367) Batch 1.585 (4.981) Remain 10:44:51 Loss 1.0988 Accuracy 0.3355.
[2022-09-03 18:52:13,576 INFO train_south.py line 279 39176] Epoch: [1/150][33/52] Data 0.002 (3.265) Batch 1.563 (4.877) Remain 10:31:22 Loss 1.0991 Accuracy 0.3322.
[2022-09-03 18:52:15,131 INFO train_south.py line 279 39176] Epoch: [1/150][34/52] Data 0.001 (3.169) Batch 1.555 (4.780) Remain 10:18:38 Loss 1.0989 Accuracy 0.3323.
[2022-09-03 18:52:16,689 INFO train_south.py line 279 39176] Epoch: [1/150][35/52] Data 0.001 (3.079) Batch 1.558 (4.688) Remain 10:06:38 Loss 1.0988 Accuracy 0.3344.
[2022-09-03 18:52:18,253 INFO train_south.py line 279 39176] Epoch: [1/150][36/52] Data 0.001 (2.993) Batch 1.564 (4.601) Remain 09:55:20 Loss 1.0989 Accuracy 0.3327.
[2022-09-03 18:52:19,827 INFO train_south.py line 279 39176] Epoch: [1/150][37/52] Data 0.001 (2.912) Batch 1.574 (4.519) Remain 09:44:40 Loss 1.0988 Accuracy 0.3336.
[2022-09-03 18:52:21,469 INFO train_south.py line 279 39176] Epoch: [1/150][38/52] Data 0.002 (2.836) Batch 1.642 (4.443) Remain 09:34:48 Loss 1.0988 Accuracy 0.3337.
[2022-09-03 18:52:23,029 INFO train_south.py line 279 39176] Epoch: [1/150][39/52] Data 0.002 (2.763) Batch 1.560 (4.369) Remain 09:25:10 Loss 1.0988 Accuracy 0.3341.
[2022-09-03 18:52:24,611 INFO train_south.py line 279 39176] Epoch: [1/150][40/52] Data 0.001 (2.694) Batch 1.582 (4.300) Remain 09:16:05 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 18:52:26,167 INFO train_south.py line 279 39176] Epoch: [1/150][41/52] Data 0.001 (2.628) Batch 1.556 (4.233) Remain 09:07:21 Loss 1.0987 Accuracy 0.3338.
[2022-09-03 18:52:27,725 INFO train_south.py line 279 39176] Epoch: [1/150][42/52] Data 0.001 (2.566) Batch 1.558 (4.169) Remain 08:59:03 Loss 1.0988 Accuracy 0.3336.
[2022-09-03 18:52:29,416 INFO train_south.py line 279 39176] Epoch: [1/150][43/52] Data 0.001 (2.506) Batch 1.690 (4.111) Remain 08:51:32 Loss 1.0987 Accuracy 0.3334.
[2022-09-03 18:52:30,985 INFO train_south.py line 279 39176] Epoch: [1/150][44/52] Data 0.003 (2.449) Batch 1.570 (4.054) Remain 08:44:00 Loss 1.0988 Accuracy 0.3324.
[2022-09-03 18:52:32,545 INFO train_south.py line 279 39176] Epoch: [1/150][45/52] Data 0.001 (2.395) Batch 1.560 (3.998) Remain 08:36:46 Loss 1.0988 Accuracy 0.3328.
[2022-09-03 18:52:34,193 INFO train_south.py line 279 39176] Epoch: [1/150][46/52] Data 0.002 (2.343) Batch 1.648 (3.947) Remain 08:30:06 Loss 1.0987 Accuracy 0.3331.
[2022-09-03 18:52:35,759 INFO train_south.py line 279 39176] Epoch: [1/150][47/52] Data 0.002 (2.293) Batch 1.566 (3.896) Remain 08:23:29 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 18:52:37,384 INFO train_south.py line 279 39176] Epoch: [1/150][48/52] Data 0.001 (2.245) Batch 1.626 (3.849) Remain 08:17:18 Loss 1.0987 Accuracy 0.3336.
[2022-09-03 18:52:38,939 INFO train_south.py line 279 39176] Epoch: [1/150][49/52] Data 0.001 (2.200) Batch 1.554 (3.802) Remain 08:11:11 Loss 1.0987 Accuracy 0.3339.
[2022-09-03 18:52:40,497 INFO train_south.py line 279 39176] Epoch: [1/150][50/52] Data 0.002 (2.156) Batch 1.558 (3.757) Remain 08:05:20 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 18:52:42,177 INFO train_south.py line 279 39176] Epoch: [1/150][51/52] Data 0.001 (2.113) Batch 1.680 (3.717) Remain 08:00:00 Loss 1.0987 Accuracy 0.3335.
[2022-09-03 18:52:43,747 INFO train_south.py line 279 39176] Epoch: [1/150][52/52] Data 0.008 (2.073) Batch 1.570 (3.675) Remain 07:54:37 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 18:52:43,928 INFO train_south.py line 301 39176] Train result at epoch [1/150]: mIoU/mAcc/allAcc 0.1979/0.3334/0.3334.
[2022-09-03 18:52:43,931 INFO train_south.py line 307 39176] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 18:53:38,184 INFO train_south.py line 346 39176] Test: [1/1] Data 14.778 (14.778) Batch 54.248 (54.248) Loss 1.0987 (1.0987) Accuracy 0.3345.
[2022-09-03 18:53:38,393 INFO train_south.py line 363 39176] Val result: mIoU/mAcc/allAcc 0.1644/0.3342/0.3345.
[2022-09-03 18:53:38,394 INFO train_south.py line 365 39176] Class_0 Result: iou/accuracy 0.0564/0.0635.
[2022-09-03 18:53:38,394 INFO train_south.py line 365 39176] Class_1 Result: iou/accuracy 0.3012/0.7535.
[2022-09-03 18:53:38,394 INFO train_south.py line 365 39176] Class_2 Result: iou/accuracy 0.1356/0.1856.
[2022-09-03 18:53:38,394 INFO train_south.py line 366 39176] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2022-09-03 18:53:38,395 INFO train_south.py line 217 39176] Saving checkpoint to: exp/south/pointtransformer_repro/model/model_last.pth
[2022-09-03 18:53:38,712 INFO train_south.py line 221 39176] Best validation mIoU updated to: 0.1644
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 18:54:23,434 INFO train_south.py line 279 39176] Epoch: [2/150][1/52] Data 42.798 (42.798) Batch 44.445 (44.445) Remain 95:38:37 Loss 1.0987 Accuracy 0.3336.
[2022-09-03 18:54:35,254 INFO train_south.py line 279 39176] Epoch: [2/150][2/52] Data 10.246 (26.522) Batch 11.821 (28.133) Remain 60:31:58 Loss 1.0987 Accuracy 0.3329.
[2022-09-03 18:54:36,822 INFO train_south.py line 279 39176] Epoch: [2/150][3/52] Data 0.002 (17.682) Batch 1.567 (19.278) Remain 41:28:26 Loss 1.0987 Accuracy 0.3336.
[2022-09-03 18:54:38,376 INFO train_south.py line 279 39176] Epoch: [2/150][4/52] Data 0.002 (13.262) Batch 1.554 (14.847) Remain 31:56:14 Loss 1.0986 Accuracy 0.3340.
[2022-09-03 18:54:39,930 INFO train_south.py line 279 39176] Epoch: [2/150][5/52] Data 0.001 (10.610) Batch 1.554 (12.188) Remain 26:12:54 Loss 1.0987 Accuracy 0.3345.
[2022-09-03 18:54:41,494 INFO train_south.py line 279 39176] Epoch: [2/150][6/52] Data 0.002 (8.842) Batch 1.564 (10.418) Remain 22:24:12 Loss 1.0987 Accuracy 0.3333.
[2022-09-03 18:54:50,022 INFO train_south.py line 279 39176] Epoch: [2/150][7/52] Data 6.957 (8.573) Batch 8.528 (10.148) Remain 21:49:12 Loss 1.0986 Accuracy 0.3347.
[2022-09-03 18:54:51,575 INFO train_south.py line 279 39176] Epoch: [2/150][8/52] Data 0.001 (7.501) Batch 1.554 (9.073) Remain 19:30:27 Loss 1.0987 Accuracy 0.3326.
[2022-09-03 18:54:53,144 INFO train_south.py line 279 39176] Epoch: [2/150][9/52] Data 0.002 (6.668) Batch 1.569 (8.239) Remain 17:42:45 Loss 1.0986 Accuracy 0.3347.
[2022-09-03 18:55:15,465 INFO train_south.py line 279 39176] Epoch: [2/150][10/52] Data 20.564 (8.057) Batch 22.320 (9.648) Remain 20:44:13 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:55:17,023 INFO train_south.py line 279 39176] Epoch: [2/150][11/52] Data 0.003 (7.325) Batch 1.559 (8.912) Remain 19:09:14 Loss 1.0986 Accuracy 0.3338.
[2022-09-03 18:55:18,580 INFO train_south.py line 279 39176] Epoch: [2/150][12/52] Data 0.001 (6.715) Batch 1.556 (8.299) Remain 17:50:03 Loss 1.0987 Accuracy 0.3326.
[2022-09-03 18:55:20,145 INFO train_south.py line 279 39176] Epoch: [2/150][13/52] Data 0.001 (6.198) Batch 1.566 (7.781) Remain 16:43:08 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:55:21,720 INFO train_south.py line 279 39176] Epoch: [2/150][14/52] Data 0.002 (5.756) Batch 1.575 (7.338) Remain 15:45:51 Loss 1.0987 Accuracy 0.3336.
[2022-09-03 18:55:23,289 INFO train_south.py line 279 39176] Epoch: [2/150][15/52] Data 0.005 (5.372) Batch 1.569 (6.953) Remain 14:56:10 Loss 1.0987 Accuracy 0.3330.
[2022-09-03 18:55:24,878 INFO train_south.py line 279 39176] Epoch: [2/150][16/52] Data 0.002 (5.037) Batch 1.589 (6.618) Remain 14:12:51 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 18:55:26,500 INFO train_south.py line 279 39176] Epoch: [2/150][17/52] Data 0.002 (4.741) Batch 1.622 (6.324) Remain 13:34:52 Loss 1.0986 Accuracy 0.3330.
[2022-09-03 18:55:28,123 INFO train_south.py line 279 39176] Epoch: [2/150][18/52] Data 0.005 (4.478) Batch 1.623 (6.063) Remain 13:01:07 Loss 1.0986 Accuracy 0.3349.
[2022-09-03 18:55:29,695 INFO train_south.py line 279 39176] Epoch: [2/150][19/52] Data 0.003 (4.242) Batch 1.572 (5.827) Remain 12:30:34 Loss 1.0987 Accuracy 0.3333.
[2022-09-03 18:55:31,350 INFO train_south.py line 279 39176] Epoch: [2/150][20/52] Data 0.001 (4.030) Batch 1.655 (5.618) Remain 12:03:36 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:55:32,913 INFO train_south.py line 279 39176] Epoch: [2/150][21/52] Data 0.001 (3.838) Batch 1.564 (5.425) Remain 11:38:38 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 18:55:34,718 INFO train_south.py line 279 39176] Epoch: [2/150][22/52] Data 0.002 (3.664) Batch 1.804 (5.260) Remain 11:17:21 Loss 1.0987 Accuracy 0.3337.
[2022-09-03 18:55:36,279 INFO train_south.py line 279 39176] Epoch: [2/150][23/52] Data 0.002 (3.505) Batch 1.562 (5.100) Remain 10:56:34 Loss 1.0987 Accuracy 0.3334.
[2022-09-03 18:55:37,846 INFO train_south.py line 279 39176] Epoch: [2/150][24/52] Data 0.001 (3.359) Batch 1.567 (4.952) Remain 10:37:32 Loss 1.0987 Accuracy 0.3333.
[2022-09-03 18:55:39,572 INFO train_south.py line 279 39176] Epoch: [2/150][25/52] Data 0.002 (3.224) Batch 1.725 (4.823) Remain 10:20:50 Loss 1.0987 Accuracy 0.3337.
[2022-09-03 18:55:41,183 INFO train_south.py line 279 39176] Epoch: [2/150][26/52] Data 0.002 (3.100) Batch 1.611 (4.700) Remain 10:04:51 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 18:55:42,746 INFO train_south.py line 279 39176] Epoch: [2/150][27/52] Data 0.002 (2.986) Batch 1.563 (4.584) Remain 09:49:50 Loss 1.0986 Accuracy 0.3332.
[2022-09-03 18:55:44,321 INFO train_south.py line 279 39176] Epoch: [2/150][28/52] Data 0.002 (2.879) Batch 1.575 (4.476) Remain 09:35:55 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 18:55:45,896 INFO train_south.py line 279 39176] Epoch: [2/150][29/52] Data 0.002 (2.780) Batch 1.575 (4.376) Remain 09:22:59 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 18:55:47,457 INFO train_south.py line 279 39176] Epoch: [2/150][30/52] Data 0.002 (2.687) Batch 1.561 (4.282) Remain 09:10:50 Loss 1.0986 Accuracy 0.3342.
[2022-09-03 18:55:49,017 INFO train_south.py line 279 39176] Epoch: [2/150][31/52] Data 0.001 (2.601) Batch 1.560 (4.194) Remain 08:59:28 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:55:50,587 INFO train_south.py line 279 39176] Epoch: [2/150][32/52] Data 0.001 (2.519) Batch 1.570 (4.112) Remain 08:48:51 Loss 1.0987 Accuracy 0.3340.
[2022-09-03 18:55:52,155 INFO train_south.py line 279 39176] Epoch: [2/150][33/52] Data 0.002 (2.443) Batch 1.568 (4.035) Remain 08:38:52 Loss 1.0987 Accuracy 0.3342.
[2022-09-03 18:55:53,725 INFO train_south.py line 279 39176] Epoch: [2/150][34/52] Data 0.001 (2.371) Batch 1.570 (3.963) Remain 08:29:29 Loss 1.0987 Accuracy 0.3328.
[2022-09-03 18:55:55,342 INFO train_south.py line 279 39176] Epoch: [2/150][35/52] Data 0.001 (2.304) Batch 1.617 (3.896) Remain 08:20:48 Loss 1.0986 Accuracy 0.3335.
[2022-09-03 18:55:56,909 INFO train_south.py line 279 39176] Epoch: [2/150][36/52] Data 0.001 (2.240) Batch 1.567 (3.831) Remain 08:12:25 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 18:55:58,574 INFO train_south.py line 279 39176] Epoch: [2/150][37/52] Data 0.002 (2.179) Batch 1.665 (3.773) Remain 08:04:50 Loss 1.0986 Accuracy 0.3336.
[2022-09-03 18:56:00,147 INFO train_south.py line 279 39176] Epoch: [2/150][38/52] Data 0.001 (2.122) Batch 1.572 (3.715) Remain 07:57:20 Loss 1.0986 Accuracy 0.3336.
[2022-09-03 18:56:01,715 INFO train_south.py line 279 39176] Epoch: [2/150][39/52] Data 0.002 (2.067) Batch 1.568 (3.660) Remain 07:50:12 Loss 1.0986 Accuracy 0.3350.
[2022-09-03 18:56:03,304 INFO train_south.py line 279 39176] Epoch: [2/150][40/52] Data 0.002 (2.016) Batch 1.589 (3.608) Remain 07:43:29 Loss 1.0986 Accuracy 0.3330.
[2022-09-03 18:56:04,879 INFO train_south.py line 279 39176] Epoch: [2/150][41/52] Data 0.002 (1.967) Batch 1.575 (3.558) Remain 07:37:03 Loss 1.0986 Accuracy 0.3343.
[2022-09-03 18:56:06,450 INFO train_south.py line 279 39176] Epoch: [2/150][42/52] Data 0.002 (1.920) Batch 1.571 (3.511) Remain 07:30:55 Loss 1.0986 Accuracy 0.3324.
[2022-09-03 18:56:08,018 INFO train_south.py line 279 39176] Epoch: [2/150][43/52] Data 0.001 (1.875) Batch 1.568 (3.466) Remain 07:25:03 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:56:09,579 INFO train_south.py line 279 39176] Epoch: [2/150][44/52] Data 0.001 (1.833) Batch 1.561 (3.423) Remain 07:19:26 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:56:11,147 INFO train_south.py line 279 39176] Epoch: [2/150][45/52] Data 0.001 (1.792) Batch 1.568 (3.381) Remain 07:14:06 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 18:56:12,723 INFO train_south.py line 279 39176] Epoch: [2/150][46/52] Data 0.002 (1.753) Batch 1.577 (3.342) Remain 07:09:00 Loss 1.0986 Accuracy 0.3331.
[2022-09-03 18:56:14,312 INFO train_south.py line 279 39176] Epoch: [2/150][47/52] Data 0.002 (1.716) Batch 1.588 (3.305) Remain 07:04:09 Loss 1.0987 Accuracy 0.3334.
[2022-09-03 18:56:15,910 INFO train_south.py line 279 39176] Epoch: [2/150][48/52] Data 0.002 (1.680) Batch 1.598 (3.269) Remain 06:59:32 Loss 1.0986 Accuracy 0.3337.
[2022-09-03 18:56:17,485 INFO train_south.py line 279 39176] Epoch: [2/150][49/52] Data 0.001 (1.646) Batch 1.575 (3.235) Remain 06:55:03 Loss 1.0986 Accuracy 0.3347.
[2022-09-03 18:56:19,049 INFO train_south.py line 279 39176] Epoch: [2/150][50/52] Data 0.002 (1.613) Batch 1.564 (3.201) Remain 06:50:42 Loss 1.0986 Accuracy 0.3338.
[2022-09-03 18:56:20,625 INFO train_south.py line 279 39176] Epoch: [2/150][51/52] Data 0.001 (1.581) Batch 1.577 (3.169) Remain 06:46:34 Loss 1.0986 Accuracy 0.3340.
[2022-09-03 18:56:22,211 INFO train_south.py line 279 39176] Epoch: [2/150][52/52] Data 0.004 (1.551) Batch 1.586 (3.139) Remain 06:42:36 Loss 1.0986 Accuracy 0.3332.
[2022-09-03 18:56:22,461 INFO train_south.py line 301 39176] Train result at epoch [2/150]: mIoU/mAcc/allAcc 0.1988/0.3335/0.3336.
[2022-09-03 18:56:22,463 INFO train_south.py line 307 39176] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 18:57:26,042 INFO train_south.py line 346 39176] Test: [1/1] Data 24.143 (24.143) Batch 63.575 (63.575) Loss 1.0986 (1.0986) Accuracy 0.3334.
[2022-09-03 18:57:26,245 INFO train_south.py line 363 39176] Val result: mIoU/mAcc/allAcc 0.1685/0.3333/0.3334.
[2022-09-03 18:57:26,246 INFO train_south.py line 365 39176] Class_0 Result: iou/accuracy 0.1547/0.2241.
[2022-09-03 18:57:26,246 INFO train_south.py line 365 39176] Class_1 Result: iou/accuracy 0.0571/0.0644.
[2022-09-03 18:57:26,246 INFO train_south.py line 365 39176] Class_2 Result: iou/accuracy 0.2937/0.7115.
[2022-09-03 18:57:26,246 INFO train_south.py line 366 39176] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2022-09-03 18:57:26,247 INFO train_south.py line 217 39176] Saving checkpoint to: exp/south/pointtransformer_repro/model/model_last.pth
[2022-09-03 18:57:26,633 INFO train_south.py line 221 39176] Best validation mIoU updated to: 0.1685
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 18:57:51,911 INFO train_south.py line 279 39176] Epoch: [3/150][1/52] Data 23.518 (23.518) Batch 25.146 (25.146) Remain 53:44:59 Loss 1.0986 Accuracy 0.3343.
[2022-09-03 18:57:53,467 INFO train_south.py line 279 39176] Epoch: [3/150][2/52] Data 0.002 (11.760) Batch 1.556 (13.351) Remain 28:32:04 Loss 1.0986 Accuracy 0.3335.
[2022-09-03 18:57:55,017 INFO train_south.py line 279 39176] Epoch: [3/150][3/52] Data 0.002 (7.841) Batch 1.550 (9.417) Remain 20:07:28 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:57:56,571 INFO train_south.py line 279 39176] Epoch: [3/150][4/52] Data 0.001 (5.881) Batch 1.555 (7.452) Remain 15:55:18 Loss 1.0986 Accuracy 0.3335.
[2022-09-03 18:57:58,121 INFO train_south.py line 279 39176] Epoch: [3/150][5/52] Data 0.001 (4.705) Batch 1.550 (6.271) Remain 13:23:52 Loss 1.0986 Accuracy 0.3350.
[2022-09-03 18:57:59,671 INFO train_south.py line 279 39176] Epoch: [3/150][6/52] Data 0.002 (3.921) Batch 1.550 (5.484) Remain 11:42:55 Loss 1.0986 Accuracy 0.3349.
[2022-09-03 18:58:01,231 INFO train_south.py line 279 39176] Epoch: [3/150][7/52] Data 0.001 (3.361) Batch 1.560 (4.924) Remain 10:30:59 Loss 1.0986 Accuracy 0.3324.
[2022-09-03 18:58:02,784 INFO train_south.py line 279 39176] Epoch: [3/150][8/52] Data 0.001 (2.941) Batch 1.553 (4.502) Remain 09:36:54 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:58:04,339 INFO train_south.py line 279 39176] Epoch: [3/150][9/52] Data 0.002 (2.615) Batch 1.555 (4.175) Remain 08:54:52 Loss 1.0986 Accuracy 0.3350.
[2022-09-03 18:58:05,890 INFO train_south.py line 279 39176] Epoch: [3/150][10/52] Data 0.002 (2.353) Batch 1.551 (3.913) Remain 08:21:12 Loss 1.0986 Accuracy 0.3329.
[2022-09-03 18:58:07,441 INFO train_south.py line 279 39176] Epoch: [3/150][11/52] Data 0.001 (2.139) Batch 1.551 (3.698) Remain 07:53:38 Loss 1.0986 Accuracy 0.3326.
[2022-09-03 18:58:08,992 INFO train_south.py line 279 39176] Epoch: [3/150][12/52] Data 0.001 (1.961) Batch 1.551 (3.519) Remain 07:30:39 Loss 1.0986 Accuracy 0.3344.
[2022-09-03 18:58:10,545 INFO train_south.py line 279 39176] Epoch: [3/150][13/52] Data 0.001 (1.810) Batch 1.553 (3.368) Remain 07:11:14 Loss 1.0986 Accuracy 0.3322.
[2022-09-03 18:58:12,097 INFO train_south.py line 279 39176] Epoch: [3/150][14/52] Data 0.002 (1.681) Batch 1.552 (3.238) Remain 06:54:34 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:58:13,655 INFO train_south.py line 279 39176] Epoch: [3/150][15/52] Data 0.002 (1.569) Batch 1.558 (3.126) Remain 06:40:11 Loss 1.0986 Accuracy 0.3347.
[2022-09-03 18:58:15,218 INFO train_south.py line 279 39176] Epoch: [3/150][16/52] Data 0.002 (1.471) Batch 1.563 (3.028) Remain 06:27:37 Loss 1.0986 Accuracy 0.3337.
[2022-09-03 18:58:16,785 INFO train_south.py line 279 39176] Epoch: [3/150][17/52] Data 0.002 (1.385) Batch 1.567 (2.942) Remain 06:16:34 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:58:18,345 INFO train_south.py line 279 39176] Epoch: [3/150][18/52] Data 0.002 (1.308) Batch 1.560 (2.866) Remain 06:06:42 Loss 1.0986 Accuracy 0.3343.
[2022-09-03 18:58:19,904 INFO train_south.py line 279 39176] Epoch: [3/150][19/52] Data 0.002 (1.239) Batch 1.559 (2.797) Remain 05:57:51 Loss 1.0986 Accuracy 0.3340.
[2022-09-03 18:58:21,464 INFO train_south.py line 279 39176] Epoch: [3/150][20/52] Data 0.001 (1.177) Batch 1.559 (2.735) Remain 05:49:53 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:58:23,024 INFO train_south.py line 279 39176] Epoch: [3/150][21/52] Data 0.001 (1.121) Batch 1.560 (2.679) Remain 05:42:41 Loss 1.0986 Accuracy 0.3331.
[2022-09-03 18:58:24,583 INFO train_south.py line 279 39176] Epoch: [3/150][22/52] Data 0.001 (1.070) Batch 1.559 (2.628) Remain 05:36:08 Loss 1.0986 Accuracy 0.3335.
[2022-09-03 18:58:26,147 INFO train_south.py line 279 39176] Epoch: [3/150][23/52] Data 0.002 (1.024) Batch 1.563 (2.582) Remain 05:30:10 Loss 1.0986 Accuracy 0.3348.
[2022-09-03 18:58:27,709 INFO train_south.py line 279 39176] Epoch: [3/150][24/52] Data 0.002 (0.981) Batch 1.562 (2.539) Remain 05:24:41 Loss 1.0986 Accuracy 0.3348.
[2022-09-03 18:58:29,266 INFO train_south.py line 279 39176] Epoch: [3/150][25/52] Data 0.001 (0.942) Batch 1.557 (2.500) Remain 05:19:38 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:58:30,825 INFO train_south.py line 279 39176] Epoch: [3/150][26/52] Data 0.001 (0.906) Batch 1.559 (2.464) Remain 05:14:57 Loss 1.0986 Accuracy 0.3345.
[2022-09-03 18:58:32,543 INFO train_south.py line 279 39176] Epoch: [3/150][27/52] Data 0.002 (0.873) Batch 1.718 (2.436) Remain 05:11:23 Loss 1.0986 Accuracy 0.3334.
[2022-09-03 18:58:34,136 INFO train_south.py line 279 39176] Epoch: [3/150][28/52] Data 0.004 (0.842) Batch 1.592 (2.406) Remain 05:07:30 Loss 1.0987 Accuracy 0.3334.
[2022-09-03 18:58:35,725 INFO train_south.py line 279 39176] Epoch: [3/150][29/52] Data 0.001 (0.813) Batch 1.590 (2.378) Remain 05:03:51 Loss 1.0986 Accuracy 0.3329.
[2022-09-03 18:58:37,291 INFO train_south.py line 279 39176] Epoch: [3/150][30/52] Data 0.001 (0.786) Batch 1.566 (2.351) Remain 05:00:21 Loss 1.0986 Accuracy 0.3345.
[2022-09-03 18:58:38,858 INFO train_south.py line 279 39176] Epoch: [3/150][31/52] Data 0.002 (0.760) Batch 1.567 (2.326) Remain 04:57:05 Loss 1.0986 Accuracy 0.3332.
[2022-09-03 18:58:40,450 INFO train_south.py line 279 39176] Epoch: [3/150][32/52] Data 0.002 (0.737) Batch 1.592 (2.303) Remain 04:54:07 Loss 1.0987 Accuracy 0.3322.
[2022-09-03 18:58:42,020 INFO train_south.py line 279 39176] Epoch: [3/150][33/52] Data 0.003 (0.714) Batch 1.570 (2.280) Remain 04:51:15 Loss 1.0987 Accuracy 0.3332.
[2022-09-03 18:58:43,584 INFO train_south.py line 279 39176] Epoch: [3/150][34/52] Data 0.001 (0.693) Batch 1.564 (2.259) Remain 04:48:31 Loss 1.0987 Accuracy 0.3329.
[2022-09-03 18:58:45,146 INFO train_south.py line 279 39176] Epoch: [3/150][35/52] Data 0.002 (0.674) Batch 1.563 (2.239) Remain 04:45:56 Loss 1.0986 Accuracy 0.3331.
[2022-09-03 18:58:46,779 INFO train_south.py line 279 39176] Epoch: [3/150][36/52] Data 0.001 (0.655) Batch 1.633 (2.223) Remain 04:43:45 Loss 1.0986 Accuracy 0.3323.
[2022-09-03 18:58:48,342 INFO train_south.py line 279 39176] Epoch: [3/150][37/52] Data 0.002 (0.637) Batch 1.563 (2.205) Remain 04:41:26 Loss 1.0986 Accuracy 0.3332.
[2022-09-03 18:58:50,000 INFO train_south.py line 279 39176] Epoch: [3/150][38/52] Data 0.001 (0.620) Batch 1.658 (2.190) Remain 04:39:34 Loss 1.0986 Accuracy 0.3319.
[2022-09-03 18:58:51,568 INFO train_south.py line 279 39176] Epoch: [3/150][39/52] Data 0.002 (0.605) Batch 1.569 (2.174) Remain 04:37:29 Loss 1.0986 Accuracy 0.3330.
[2022-09-03 18:58:53,134 INFO train_south.py line 279 39176] Epoch: [3/150][40/52] Data 0.001 (0.590) Batch 1.566 (2.159) Remain 04:35:31 Loss 1.0987 Accuracy 0.3327.
[2022-09-03 18:58:54,702 INFO train_south.py line 279 39176] Epoch: [3/150][41/52] Data 0.001 (0.575) Batch 1.567 (2.145) Remain 04:33:38 Loss 1.0986 Accuracy 0.3326.
[2022-09-03 18:58:56,273 INFO train_south.py line 279 39176] Epoch: [3/150][42/52] Data 0.002 (0.562) Batch 1.572 (2.131) Remain 04:31:51 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:58:57,947 INFO train_south.py line 279 39176] Epoch: [3/150][43/52] Data 0.001 (0.549) Batch 1.673 (2.121) Remain 04:30:28 Loss 1.0987 Accuracy 0.3329.
[2022-09-03 18:58:59,659 INFO train_south.py line 279 39176] Epoch: [3/150][44/52] Data 0.014 (0.536) Batch 1.712 (2.111) Remain 04:29:15 Loss 1.0987 Accuracy 0.3331.
[2022-09-03 18:59:01,223 INFO train_south.py line 279 39176] Epoch: [3/150][45/52] Data 0.001 (0.524) Batch 1.564 (2.099) Remain 04:27:40 Loss 1.0986 Accuracy 0.3336.
[2022-09-03 18:59:02,813 INFO train_south.py line 279 39176] Epoch: [3/150][46/52] Data 0.002 (0.513) Batch 1.590 (2.088) Remain 04:26:13 Loss 1.0986 Accuracy 0.3349.
[2022-09-03 18:59:04,407 INFO train_south.py line 279 39176] Epoch: [3/150][47/52] Data 0.004 (0.502) Batch 1.594 (2.078) Remain 04:24:50 Loss 1.0987 Accuracy 0.3320.
[2022-09-03 18:59:05,972 INFO train_south.py line 279 39176] Epoch: [3/150][48/52] Data 0.001 (0.492) Batch 1.565 (2.067) Remain 04:23:27 Loss 1.0987 Accuracy 0.3324.
[2022-09-03 18:59:07,640 INFO train_south.py line 279 39176] Epoch: [3/150][49/52] Data 0.001 (0.482) Batch 1.668 (2.059) Remain 04:22:22 Loss 1.0986 Accuracy 0.3339.
[2022-09-03 18:59:09,225 INFO train_south.py line 279 39176] Epoch: [3/150][50/52] Data 0.005 (0.472) Batch 1.585 (2.049) Remain 04:21:08 Loss 1.0986 Accuracy 0.3341.
[2022-09-03 18:59:10,790 INFO train_south.py line 279 39176] Epoch: [3/150][51/52] Data 0.002 (0.463) Batch 1.565 (2.040) Remain 04:19:53 Loss 1.0986 Accuracy 0.3354.
[2022-09-03 18:59:12,353 INFO train_south.py line 279 39176] Epoch: [3/150][52/52] Data 0.001 (0.454) Batch 1.563 (2.031) Remain 04:18:41 Loss 1.0987 Accuracy 0.3348.
[2022-09-03 18:59:12,610 INFO train_south.py line 301 39176] Train result at epoch [3/150]: mIoU/mAcc/allAcc 0.1969/0.3335/0.3336.
[2022-09-03 18:59:12,612 INFO train_south.py line 307 39176] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[2022-09-03 18:59:53,733 INFO train_south.py line 346 39176] Test: [1/1] Data 1.638 (1.638) Batch 41.114 (41.114) Loss 1.0986 (1.0986) Accuracy 0.3334.
[2022-09-03 18:59:53,901 INFO train_south.py line 363 39176] Val result: mIoU/mAcc/allAcc 0.1678/0.3333/0.3334.
[2022-09-03 18:59:53,902 INFO train_south.py line 365 39176] Class_0 Result: iou/accuracy 0.1148/0.1492.
[2022-09-03 18:59:53,902 INFO train_south.py line 365 39176] Class_1 Result: iou/accuracy 0.0897/0.1092.
[2022-09-03 18:59:53,902 INFO train_south.py line 365 39176] Class_2 Result: iou/accuracy 0.2987/0.7413.
[2022-09-03 18:59:53,902 INFO train_south.py line 366 39176] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2022-09-03 18:59:53,903 INFO train_south.py line 217 39176] Saving checkpoint to: exp/south/pointtransformer_repro/model/model_last.pth
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
